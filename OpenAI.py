import pandas as pd
import openai
import os
from datetime import datetime
from pyspark.sql import  Row
from pyspark.sql.functions import lit
from dotenv import load_dotenv

db_properties = {
    "driver": "com.mysql.cj.jdbc.Driver",
    "user": "root",
    "password": "5941"
}

load_dotenv()
OpenAI_KEY = os.getenv("OpenAI_KEY")

#  1. API í‚¤ ì„¤ì •
openai.api_key = OpenAI_KEY

def ask_gpt(spark, search, user_id, user_message):
    '''ì§ˆë¬¸í•˜ê³  ì‘ë‹µ ë°›ê¸°'''
    # 1. ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
    history = load_history_from_spark(spark, search, user_id)

    # 2. ê¸°ì—… ë‰´ìŠ¤ ìš”ì•½ ë°ì´í„° í¬í•¨
    news_summary = fetch_news_summary(spark, search, max_count=5)

    messages = [
        {
            "role": "system",
            "content": (
                "ë‹¹ì‹ ì€ ê¸ˆìœµ ì‹œì¥ ì „ë¬¸ê°€ì´ë©°, íŠ¹íˆ ê¸°ì—… ë‰´ìŠ¤, ì¬ë¬´ ë°ì´í„°, ì‚°ì—… íŠ¸ë Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ "
                "ì£¼ì‹ì— ëŒ€í•œ ì¢…í•©ì  ë¶„ì„ê³¼ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” AI ì£¼ì‹ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. "
                "ë‹¤ìŒ í•­ëª©ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:\n\n"
                "1. ğŸ” í•µì‹¬ ì´ìŠˆ ë¶„ì„\n"
                "2. ğŸ“Š ìˆ˜ì¹˜ ê¸°ë°˜ ì„¤ëª…\n"
                "3. ğŸ§  í†µì°° ì œê³µ\n"
                "4. âš ï¸ ë¦¬ìŠ¤í¬ íŒë‹¨\n"
                "5. ğŸ”® í–¥í›„ ì „ë§\n\n"
                f"ë‹¤ìŒì€ '{search}'ì— ëŒ€í•œ ìµœê·¼ ë‰´ìŠ¤ ìš”ì•½ì…ë‹ˆë‹¤:\n\n"
                f"{news_summary}\n\n"
                "ì´ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë¶„ì„ì ìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”."
            )
        }
    ]

    # 3. ì´ì „ ëŒ€í™” ê¸°ë¡ ë°˜ì˜
    messages += [{"role": row["role"].strip(), "content": row["content"]} for row in history]

    # 4. ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    messages.append({"role": "user", "content": user_message})

    # 5. GPT í˜¸ì¶œ
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=messages
    )

    reply = response["choices"][0]["message"]["content"]

    # 6. ëŒ€í™” ì €ì¥
    save_message_to_spark(spark, search, user_id, "user", user_message)
    save_message_to_spark(spark, search, user_id, "assistant", reply)

    return reply

def load_history_from_spark(spark, search, user_id):
    '''DBì—ì„œ ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°'''
    try:
        query = f"""
            SELECT role, content FROM conversation_history
            WHERE user_id = '{user_id} and search = {search}'
            ORDER BY timestamp DESC
            limit 10
        """
        return spark.sql(query).collect()
    except Exception as e:
        print("[ERROR] History Load Failed:", e)
        return []

def save_message_to_spark(spark, search, user_id, role, content):
    '''ëŒ€í™” ê¸°ë¡ ì €ì¥í•˜ê¸°'''
    ip = "127.0.0.1"
    port = "3306" 
    db = 'news_project'

    url = f"jdbc:mysql://{ip}:{port}/{db}"
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    row = Row(user_id=user_id, search =search, role=role, content=content, timestamp=now)
    df = spark.createDataFrame([row])

    df.write.format("jdbc").options(
        url=url,
        dbtable='conversation_history',
        **db_properties
    ).mode("append").save()

def fetch_news_summary(spark, stock_name, max_count=10):
    # DBì—ì„œ í•´ë‹¹ ê¸°ì—… ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    query = f"""
        SELECT title, content, date
        FROM search_information
        WHERE search = '{stock_name}'
        ORDER BY date DESC
        LIMIT {max_count}
    """
    df = spark.sql(query)
    news_list = df.collect()

    # í…ìŠ¤íŠ¸ë¡œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"ë‹¤ìŒì€ {stock_name}ì— ëŒ€í•œ ìµœê·¼ ë‰´ìŠ¤ì…ë‹ˆë‹¤.\n\n"
    for i, row in enumerate(news_list, 1):
        prompt += f"[{i}] ì œëª©: {row['title']}\në‚ ì§œ: {row['date']}\në‚´ìš©: {row['content'][:500]}...\n\n"

    prompt += (
        f"ìœ„ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ì „ë¬¸ê°€ì²˜ëŸ¼ ë‹µí•´ì£¼ì„¸ìš”.\n"
    )
    return prompt

# # ğŸ“¥ 2. CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
# def load_news_csv(filename):
#     filepath = os.path.normpath(filename)
#     # íŒŒì¼ ì½ê¸°
#     print(f"[DEBUG] ë¶ˆëŸ¬ì˜¬ íŒŒì¼ ê²½ë¡œ: {filepath}")
#     df = pd.read_csv(filepath, encoding='utf-8-sig')  # ì¸ì½”ë”© ì•ˆì •ì„± í™•ë³´
#     return df[['title', 'content','date']]

# # âœï¸ 3. í”„ë¡¬í”„íŠ¸ ìƒì„± (ì „ì²´ ê¸°ì‚¬)
# def create_prompt_all(news_df, max_count=10):
#     prompt = """ë‹¹ì‹ ì€ ë›°ì–´ë‚œ ì‹œì¥ ë¶„ì„ê°€ì´ë©°, ì•„ë˜ëŠ” íŠ¹ì • ê¸°ì—… ë˜ëŠ” ì‚°ì—… ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ ë°ì´í„°ì…ë‹ˆë‹¤.
#             ê¸°ì‚¬ ì œëª©ê³¼ ë³¸ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒì˜ ê´€ì ì—ì„œ ì¢…í•©ì ì¸ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
#             1. ğŸ” í•µì‹¬ ì´ìŠˆ ìš”ì•½: ì£¼ìš” ì‚¬ê±´ì´ë‚˜ ë³€í™”ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
#             2. ğŸ“Š ì‹œì¥ ì˜í–¥ ë¶„ì„: í•´ë‹¹ ì‚¬ê±´ì´ ì‚°ì—… ì „ì²´ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì³¤ë‚˜ìš”?
#             3. ğŸ¢ ê¸°ì—… ì „ëµ í‰ê°€: ê´€ë ¨ ê¸°ì—…ì€ ì–´ë–¤ ì „ëµì„ í¼ì¹˜ê³  ìˆìœ¼ë©°, ê·¸ ì„±ê³¼ëŠ” ì–´ë–¤ê°€ìš”?
#             4. âš ï¸ ë¦¬ìŠ¤í¬ ìš”ì†Œ: í•´ë‹¹ ì´ìŠˆë¡œ ì¸í•´ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìœ„í—˜ ìš”ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?
#             5. ğŸ”® í–¥í›„ ì „ë§: ì‹œì¥ ë˜ëŠ” ê¸°ì—…ì˜ í–¥í›„ ë°©í–¥ì€ ì–´ë–»ê²Œ ì˜ˆì¸¡ë˜ë‚˜ìš”?\n\n"""
    
#     for i, row in news_df.head(max_count).iterrows():  # ìµœëŒ€ max_countê°œê¹Œì§€ë§Œ ì‚¬ìš©
#         prompt += f"[{i+1}] ì œëª©: {row['title']}\në‚´ìš©: {row['content'][:500]}...\n\n"  # ë³¸ë¬¸ ì¼ë¶€ë§Œ
#     prompt += "ì „ì²´ ë¶„ì„ì€ ìš”ì•½ì´ ì•„ë‹Œ, **ì „ë¬¸ê°€ ì‹œê°ì˜ í†µí•© ë¶„ì„ ë³´ê³ ì„œ í˜•íƒœ**ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
#     return prompt

# # ğŸ¤– 4. GPT ìš”ì²­
# def ask_gpt(prompt):
#     response = openai.ChatCompletion.create(
#         model="gpt-3.5-turbo", #gpt-4o-mini
#         messages=[
#             {"role": "system", "content": "ë„ˆëŠ” íˆ¬ì ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì• ë„ë¦¬ìŠ¤íŠ¸ì•¼. ì‹œì¥ íë¦„ì„ ìˆ˜ì¹˜ì™€ ì „ëµ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•´."},
#             {"role": "user", "content": prompt}
#         ],
#         temperature=0.7
#     )
#     return response['choices'][0]['message']['content']

# # âœ… ì‹¤í–‰
# def run(search):
#     filename = os.path.join("Daum_Crawling\csv_folder", f"data_{search}.csv")
#     df = load_news_csv(filename)
#     prompt = create_prompt_all(df, max_count=10)
#     summary = ask_gpt(prompt)

#     print("ğŸ“Š GPT ë¶„ì„ ê²°ê³¼:")
#     print(summary)

#âœ” ë°©ë²• 2: íŒŒì¼ ê²½ë¡œì— í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì „ì²´ ê²½ë¡œë¡œ ì§€ì •
#df = load_news_csv(r"C:\JaeHyeok\Crawling\Daum_Crawling\news_data_ìµœê·¼ë‰´ìŠ¤.csv")\

