import os
import json
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
import time

def  stock_news():
    # 1. ì…€ë ˆë‹ˆì›€ìœ¼ë¡œ í˜ì´ì§€ ì—´ê¸°
    driver = webdriver.Chrome()
    driver.get("https://finance.daum.net/news#stock")
    time.sleep(2)  # í˜ì´ì§€ ë Œë”ë§ ëŒ€ê¸°

    html = driver.page_source
    soup = BeautifulSoup(html, 'html.parser')
    driver.quit()

    # 2. ë‰´ìŠ¤ í•­ëª© ì°¾ê¸°
    news_items = soup.find_all('li', class_='imgB')

    # 3. ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ìˆ˜ì§‘
    news_data = []
    for item in news_items:
        title_tag = item.find('a', class_='tit')
        title = title_tag.text.strip() if title_tag else ''

        text_tag = item.find('a', class_='txt')
        text = text_tag.text.strip() if text_tag else ''

        article_url = title_tag['href'] if title_tag else ''

        img_tag = item.find('img')
        img_url = img_tag['src'] if img_tag else ''

        date_tag = item.find('p', class_='date')
        source, date = '', ''
        if date_tag:
            parts = date_tag.text.strip().split('Â·')
            if len(parts) == 2:
                source = parts[0].strip()
                date = parts[1].strip()

        news_data.append({
            'ì œëª©': title,
            'ìš”ì•½': text,
            'ì´ë¯¸ì§€_URL': img_url,
            'ê¸°ì‚¬_URL': article_url,
            'ë‰´ìŠ¤ì‚¬': source,
            'ë‚ ì§œ': date
        })

    # 4. DataFrame ìƒì„±
    df = pd.DataFrame(news_data)

    # 5. JSONìœ¼ë¡œ ì €ì¥
    base_dir = os.path.dirname(os.path.abspath(__file__))

    # ê°™ì€ ë””ë ‰í† ë¦¬ì— JSON ì €ì¥
    json_path = os.path.join(base_dir, "stock_news.json")
    df.to_json(json_path, orient='records', force_ascii=False, indent=4)

    json_str = df.to_json(orient='records', force_ascii=False, indent=4)
    # ğŸ‘‰ JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ê°ì²´ë¡œ ë¡œë“œí•´ì„œ ë¦¬í„´
    return json.loads(json_str)
